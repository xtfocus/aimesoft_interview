{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274c7f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2f925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/tung/units/python_dev/tung_aimesoft_solution/repo/codes/experiment_tracking/mlruns/1', creation_time=1708886061134, experiment_id='1', last_update_time=1708886061134, lifecycle_stage='active', name='bert-restaurant-sentiment-classification', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from model import SentimentClassifierUntrainedCLSMultiLastLayersMultiLinear\n",
    "from data_preprocessing import create_data_loader,\\\n",
    "                                tokenizer,\\\n",
    "                                df_train,\\\n",
    "                                df_dev,\\\n",
    "                                df_test,\\\n",
    "                                dev_data_loader,\\\n",
    "                                test_data_loader,\\\n",
    "                                dev_size,\\\n",
    "                                MAX_LEN,\\\n",
    "                                BATCH_SIZE,\\\n",
    "                                class_names\n",
    "\n",
    "import pandas as pd\n",
    "from train import DEVICE, optimizer_scheduler, train_model, train_epoch, eval_model, loss_fn\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"bert-restaurant-sentiment-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0311d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_total = pd.concat([df_train, df_dev])\n",
    "total_train_data_loader = create_data_loader(df_train_total, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "train_size = df_train_total.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca197871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_scheduler(model):\n",
    "    \n",
    "    # Optimizer Adam \n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
    "    \n",
    "    total_steps = len(total_train_data_loader) * EPOCHS\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=5,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    return optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05bccebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n",
      "Train loss 0.5344890259720129 accuracy 0.6844444444444444\n",
      "Val   loss 0.11130647361278534 accuracy 0.96\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "Train loss 0.14699410299513618 accuracy 0.9355555555555556\n",
      "Val   loss 0.011812818835356407 accuracy 1.0\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "Train loss 0.030995305675756316 accuracy 0.9911111111111112\n",
      "Val   loss 0.00349374017345586 accuracy 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "model = SentimentClassifierUntrainedCLSMultiLastLayersMultiLinear(len(class_names))\n",
    "model = model.to(DEVICE)\n",
    "optimizer, scheduler = optimizer_scheduler(model)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"Model class\", \"SentimentClassifierUntrainedCLSMultiLastLayersMultiLinear\")\n",
    "\n",
    "    history = defaultdict(list)\n",
    "    best_accuracy = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        # Show details \n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        train_acc, train_loss = train_epoch(\n",
    "            model,\n",
    "            total_train_data_loader,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            DEVICE,\n",
    "            scheduler,\n",
    "            train_size,\n",
    "            epoch\n",
    "        )\n",
    "        \n",
    "        print(f\"Train loss {train_loss} accuracy {train_acc}\")\n",
    "        \n",
    "        # Get model performance (accuracy and loss)\n",
    "        val_acc, val_loss = eval_model(\n",
    "            model,\n",
    "            dev_data_loader,\n",
    "            loss_fn,\n",
    "            DEVICE,\n",
    "            dev_size\n",
    "        )\n",
    "        \n",
    "        print(f\"Val   loss {val_loss} accuracy {val_acc}\")\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        mlflow.log_metric(\"Train Loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"Val  Loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"Train Accuracy\", train_acc, step=epoch)\n",
    "        mlflow.log_metric(\"Val Accuracy\", val_acc, step=epoch)\n",
    "\n",
    "        \n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # If we beat prev performance\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            best_epoch = epoch\n",
    "            mlflow.pytorch.log_model(\n",
    "                model, artifact_path=\"{}-{}\".format(best_epoch, best_accuracy), \n",
    "            )\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2868f5d0",
   "metadata": {},
   "source": [
    "Inference on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab872713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import eval_model\n",
    "\n",
    "acc, loss = eval_model(model, test_data_loader, loss_fn, DEVICE, len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81027d",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01de4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "from inference import get_predictions\n",
    "\n",
    "y_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "    model,\n",
    "    test_data_loader,\n",
    "    DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a8d1e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        50\n",
      "           1       0.96      0.98      0.97        50\n",
      "\n",
      "    accuracy                           0.97       100\n",
      "   macro avg       0.97      0.97      0.97       100\n",
      "weighted avg       0.97      0.97      0.97       100\n",
      "\n",
      "[[48  2]\n",
      " [ 1 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c92cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4565"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "del(model)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
